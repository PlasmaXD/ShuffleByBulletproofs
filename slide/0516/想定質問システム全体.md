
---

## 1. なぜCount–Min Sketch（CMS）を選んだのか？

**質問例**

> RAPPORの候補リスト問題に対して、なぜBloomフィルタではなくCMSを採用したのですか？

**回答例**

> Bloomフィルタはビット列の「集合判定」には向いていますが、要素ごとの頻度推定には適していません。一方CMSは、固定メモリ内で各要素の出現回数を近似的に保持でき、ランダムノイズと組み合わせても誤差を定量的に制御できるため、頻度集計用途に最適です。

---

## 2. CMSの誤差保証はどの程度か？

**質問例**

> CMSを使った場合、どれくらいの誤差が許容されるのか教えてください。

**回答例**

> CMSは真の頻度 $f_i$ に対して、$\hat f_i \le f_i + \epsilon N$ を保証します。たとえば $\epsilon=0.01$，$\delta=0.01$ と設定すれば、総サンプル数 $N$ の1%以内の誤差で、99%の確率で推定できます。

---

## 3. ランダムノイズ(IRR)による精度低下は？

**質問例**

> IRRでノイズを入れると誤差がさらに増えそうですが、大丈夫ですか？

**回答例**

> たしかにノイズを強くすると推定誤差は増大しますが、IRRのパラメータ $p, q$ を調整することで、プライバシー保証と精度のトレードオフを最適化できます。実験では、適切なスケッチサイズとノイズ強度の組み合わせでMAEが数%以内に収まりました。

---

## 4. 計算コストと通信オーバーヘッドは？

**質問例**

> クライアント側とサーバー側の負荷はどのくらいですか？

**回答例**

> クライアント側はハッシュ関数 $d$ 回の計算と1セルのインクリメント、さらにIRRの乱択のみなので $O(d)$ 時間です。通信はCMSの各行で＋1したセル位置のインデックス（整数）を送るだけで済むため、オーバーヘッドは非常に小さいです。

---

## 5. 既存手法との比較は？

**質問例**

> 他の頻度推定手法（例：HyperLogLogやスペースセービング）はどうですか？

**回答例**

> HyperLogLogは重複排除で使われ、カーディナリティ推定に特化します。スペースセービングはトップ-k 項目抽出に優れますが、任意の要素頻度推定にはCMSほど汎用的ではありません。本手法は「任意URLの頻度推定」を低コストで行う点が特徴です。

---

## 6. 辞書不要の安全性は？

**質問例**

> 辞書を使わないとサーバー側でURLの正当性を担保できないのでは？

**回答例**

> サーバーはSketch内のセル値を元にURLごとの頻度を推定しますが、推定対象URLを指定する際には何らかの候補リストが必要です。しかし「全URL」ではなく「検証対象URL群」だけをリスト化すればよく、辞書サイズは大幅に削減できます。

---

## 7. 実験結果の詳細は？

**質問例**

> 実際に何件程度でどのくらいの誤差が出ましたか？

**回答例**

> 数千件のダミーユーザ履歴を生成し、行数 $d=5$、列数 $w=256$ のSketchで評価したところ、MAEが平均0.8%程度、MAPEが平均5%以内に収まりました。

---

## 8. 今後の展開・改善点は？

**質問例**

> 次に取り組むべき技術的課題は何ですか？

**回答例**

> 1. **自動最適化機構**：SketchサイズやIRRパラメータを動的に調整する仕組みの構築
> 2. **バッチ検証**：大規模データ（数万～数十万件）での性能評価
> 3. **リアルタイム可視化**：ダッシュボード上で集計結果を即時表示

---

## 9. セキュリティ・プライバシー保証は？

**質問例**

> 本手法でどの程度のプライバシー保証が得られますか？

**回答例**

> IRRにより各レポートは $\varepsilon$-ローカルDPを満たします。さらにCMS自体は公開情報のみを扱うため、サーバー側でプライバシー総量を評価しやすく、全体として強いDP保証を構築可能です。

---

## 10. 実運用での留意点は？

**質問例**

> 本番環境で運用するとき、どんな点に注意すべきですか？

**回答例**

> * ハッシュ関数の衝突耐性を十分に検証すること
> * Sketchサイズはデータ総量に応じて適切に設定すること
> * 定期的にパラメータ調整し、精度とプライバシー保証をバランスさせること

---

